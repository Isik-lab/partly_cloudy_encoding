{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715b12e5",
   "metadata": {},
   "source": [
    "<h1>Clean and prepare subject data</h1>\n",
    "<p>Data preparation consists of:\n",
    "    <ul>\n",
    "        <li>Nuisance regression</li>\n",
    "        <li>Group mask generation</li>\n",
    "        <li>ISC mask generation</li>\n",
    "        <li>Data normalization</li>\n",
    "        <li>Trimming blank TRs and offsetting to account for hemodyamic lag\n",
    "    </ul>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f227a0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mybrainiak/lib/python3.7/site-packages/nilearn/datasets/__init__.py:96: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "#### Imports\n",
    "import os \n",
    "import numpy as np\n",
    "import data_prep_helpers as helpers\n",
    "\n",
    "# Notebook specific imports\n",
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf67140",
   "metadata": {},
   "source": [
    "<h2>Set subject groups</h2>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li><b>Subject IDs for 3 year olds:</b> 6, 8, 9, 11, 12, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 27, 28</li>\n",
    "        <li><b>Subject IDs for 4 year olds:</b> 1, 2, 3, 4, 5, 7, 10, 15, 18, 21, 24, 29, 30 31</li>\n",
    "        <li><b>Subject IDs for 5 year olds:</b> 32-65</li>\n",
    "        <li><b>Subject IDs for 7 year olds:</b> 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 83, 84, 86, 88, 96, 99, 114, 116, 122</li>\n",
    "        <li><b>Subject IDs for 8-12 year olds:</b> 77, 78, 82, 85, 87, 89, 90, 91, 92, 93, 94, 95, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121</li>\n",
    "        <li><b>Subject IDs for adults:</b> 123-155</li>       \n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5bbdb0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data location: /Users/angira/Documents/Data/3-4-yrs\n"
     ]
    }
   ],
   "source": [
    "# Modify this section to change subject group.\n",
    "subject_group_str = '3-4-yrs'\n",
    "subject_ids = range(1,32)\n",
    "\n",
    "# Modify this section to set data location\n",
    "directory = os.path.join(os.path.expanduser('~'), 'Documents', 'Data', subject_group_str)\n",
    "print('Data location:', directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae7bf0",
   "metadata": {},
   "source": [
    "<h2>BOLD data</h2>\n",
    "<p> Either load raw data and apply nuisance regression, or load pre-cleaned data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5424ee2",
   "metadata": {},
   "source": [
    "<h3>Load and clean non-cleaned data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c065593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "cleaned_data = []\n",
    "for subject in subject_ids: \n",
    "    subject_cleaned = helpers.clean_subject_data(subject, directory, save=True)\n",
    "    cleaned_data.append(subject_cleaned)\n",
    "\n",
    "print('Cleaned data:', np.shape(cleaned_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4816b49",
   "metadata": {},
   "source": [
    "<h3>Load previously cleaned data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "171b5f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data: (31,)\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = helpers.load_clean_data(subject_ids, os.path.join(directory, 'raw_subjects'))\n",
    "print('Cleaned data:', np.shape(cleaned_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f1f6e",
   "metadata": {},
   "source": [
    "<h2>Group mask</h2>\n",
    "<p>Either generate group mask by downsampling MNI152 template from nilearn, or load previously generated mask</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ca918",
   "metadata": {},
   "source": [
    "<h3>Generate mask</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b02185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image as niimage\n",
    "\n",
    "group_mask = niimage.resample_img(img=datasets.load_mni152_brain_mask(),\n",
    "                                  target_affine=cleaned_data[0].affine,\n",
    "                                  target_shape=(79, 95, 68))\n",
    "\n",
    "print('Group mask:', np.shape(group_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574184b6",
   "metadata": {},
   "source": [
    "<h3>Load existing group mask</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b296a944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group mask: (79, 95, 68)\n"
     ]
    }
   ],
   "source": [
    "from nibabel import load as load_mask\n",
    "\n",
    "group_mask = load_mask(os.path.join(os.path.expanduser('~'), 'Documents', 'Data', 'group_mask.nii.gz'))\n",
    "print('Group mask:', np.shape(group_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99146368",
   "metadata": {},
   "source": [
    "<h2>ISC masking</h2>\n",
    "Either peform ISC or load previously performed ISC, and apply as mask to BOLD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d3195",
   "metadata": {},
   "source": [
    "<h3>Perform ISC and thresholding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d146ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully performed ISC, shape: (34, 377996)\n"
     ]
    }
   ],
   "source": [
    "# Generate ISC maps\n",
    "isc_maps = helpers.perform_isc(cleaned_data, group_mask)\n",
    "print('Successfully performed ISC, shape:', np.shape(isc_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee4e7d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153687 significant voxels after FDR controlling at threshold 0.050000\n"
     ]
    }
   ],
   "source": [
    "# Threshold ISC\n",
    "thresholded_isc, num_significant_voxels = helpers.threshold_isc(isc_maps, threshold=0.05)\n",
    "print('%d significant voxels after FDR controlling at threshold %f' %(num_significant_voxels, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f548f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unthresholed ISC values\n",
    "np.save(os.path.join(directory, (subject_group_str +'_isc.npy')), isc_maps)\n",
    "# Save thresholded ISC values\n",
    "np.save(os.path.join(directory, (subject_group_str +'_thresholded_isc.npy')), thresholded_isc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b371c",
   "metadata": {},
   "source": [
    "<h3>Load previously thresholded ISC</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1be2bc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholded ISC: (377996,)\n"
     ]
    }
   ],
   "source": [
    "thresholded_isc = np.squeeze(np.load(os.path.join(directory, (subject_group_str + '_isc_thresholded.npy'))))\n",
    "print('Thresholded ISC:', np.shape(thresholded_isc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4782b8f",
   "metadata": {},
   "source": [
    "<h3>Use adult ISC</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82dd6286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholded ISC: (377996,)\n"
     ]
    }
   ],
   "source": [
    "thresholded_isc = np.squeeze(np.load(os.path.join(os.path.expanduser('~'), \n",
    "                                                  'Documents', \n",
    "                                                  'Data', \n",
    "                                                  'adults', 'adults_isc_thresholded.npy')))\n",
    "print('Thresholded ISC:', np.shape(thresholded_isc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22143159",
   "metadata": {},
   "source": [
    "<h3>Apply ISC mask to data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2924becc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 136543, 168)\n"
     ]
    }
   ],
   "source": [
    "# Apply ISC mask to cleaned data\n",
    "masked_data = helpers.apply_isc_mask(cleaned_data, thresholded_isc, group_mask)\n",
    "print(np.shape(masked_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2bd4e",
   "metadata": {},
   "source": [
    "<h2>Normalize, trim, and shift data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e7115c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed data size: (31, 136543, 152)\n",
      "Normalized data size: (31, 136543, 152)\n"
     ]
    }
   ],
   "source": [
    "# Trim blank TRs and shift for hemodynamic lag\n",
    "trimmed_data = helpers.trim_blank_trs(masked_data)\n",
    "\n",
    "print('Trimmed data size:', np.shape(trimmed_data))\n",
    "\n",
    "# Apply normalization \n",
    "normalized_data = helpers.normalize_data(trimmed_data)\n",
    "\n",
    "print('Normalized data size:', np.shape(normalized_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf439f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved normalized data\n"
     ]
    }
   ],
   "source": [
    "# Save normalized data as numpy array\n",
    "# np.save(os.path.join(directory, (subject_group_str +'_normalized_data.npy')), normalized_data)\n",
    "np.save(os.path.join(directory, (subject_group_str +'_normalized_data_adult_mask.npy')), normalized_data)\n",
    "\n",
    "print('Successfully saved normalized data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974600f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
